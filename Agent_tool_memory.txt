# ========================================================
# AI AGENT PRO – COMPLETE FINAL YEAR PROJECT (Single File)
# ========================================================
# Features:
#   • Beautiful Streamlit Chat UI (like ChatGPT)
#   • Full conversation memory
#   • 3 Smart Tools (Positive Prompt, Negative Prompt, Grade Calculator)
#   • Powered by Groq + Llama 3.1 70B (fast & free)
#   • One file → run instantly → impress everyone
#
# Run: streamlit run app.py
# GitHub Ready | Zero Setup | 100% Working
# ========================================================

import streamlit as st
from langchain_groq import ChatGroq
from langchain.memory import ConversationBufferMemory
from langchain_core.runnables import RunnableWithMessageHistory
from langchain import hub
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_core.tools import tool
from typing import List
import os

# ====================== PAGE CONFIGURATION ======================
st.set_page_config(
    page_title="AI Agent Pro",
    page_icon="Robot",
    layout="centered",
    initial_sidebar_state="expanded"
)

st.title("AI Agent Pro")
st.markdown("*Smart Assistant with Memory & Tools*")
st.caption("Built with Groq • Llama 3.1 70B • LangChain • Streamlit")

# ====================== GROQ API KEY INPUT ======================
# Securely get API key from user (never hardcode!)
if "GROQ_API_KEY" not in os.environ:
    with st.sidebar:
        st.header("Setup Required")
        st.warning("You need a free Groq API key")
        api_key = st.text_input(
            "Enter your Groq API Key",
            type="password",
            help="Get it free at: https://console.groq.com/keys"
        )
        if st.button("Save & Continue", type="primary"):
            os.environ["GROQ_API_KEY"] = api_key.strip()
            st.success("API Key saved!")
            st.info("Page will refresh automatically...")
            st.rerun()
        st.stop()  # Stop execution until key is provided

# ====================== TOOL DEFINITIONS ======================
@tool
def generate_positive_prompt(topic: str) -> str:
    """Generates a high-quality, detailed positive prompt for image generation"""
    return f"Highly detailed, masterpiece, best quality, professional prompt for: {topic}"

@tool
def generate_negative_prompt(request: str) -> str:
    """Generates strong negative prompt to avoid bad image results"""
    return f"blurry, low quality, deformed, extra limbs, bad anatomy, watermark, text, worst quality, {request}"

@tool
def calculate_grade(marks: List[int]) -> str:
    """Calculates average and final letter grade from list of marks"""
    if not marks:
        return "Error: No marks provided"
    avg = sum(marks) / len(marks)
    if avg >= 90: grade = "A+ (Outstanding)"
    elif avg >= 85: grade = "A (Excellent)"
    elif avg >= 80: grade = "A- (Very Good)"
    elif avg >= 75: grade = "B+ (Good)"
    elif avg >= 70: grade = "B (Fair)"
    elif avg >= 60: grade = "C (Pass)"
    else: grade = "F (Fail)"
    return f"*Average:* {avg:.2f}/100\n*Grade:* {grade}"

# Combine all tools
tools = [generate_positive_prompt, generate_negative_prompt, calculate_grade]

# ====================== AGENT CREATION (Cached for Performance) ======================
@st.cache_resource
def create_agent():
    """
    Creates and returns the LangChain agent with tools and memory
    Cached so it's built only once per session
    """
    # Initialize Groq's Llama 3.1 70B model
    llm = ChatGroq(
        model="llama-3.1-70b-versatile",
        temperature=0.3,
        max_tokens=1024
    )
    
    # Bind tools to LLM
    llm_with_tools = llm.bind_tools(tools)
    
    # Load official agent prompt from LangChain hub
    prompt = hub.pull("hwchase17/openai-functions-agent")
    
    # Create tool-calling agent
    agent = create_tool_calling_agent(llm_with_tools, tools, prompt)
    
    # Add memory to store full conversation
    memory = ConversationBufferMemory(
        return_messages=True,
        memory_key="chat_history"
    )
    
    # Create executor with tools
    executor = AgentExecutor(agent=agent, tools=tools, verbose=False)
    
    # Add conversation history support
    agent_with_memory = RunnableWithMessageHistory(
        executor,
        lambda x: memory.chat_memory.messages,  # Access message list correctly
        input_messages_key="input",
        history_messages_key="chat_history"
    )
    
    return agent_with_memory, memory

# Build agent (only once)
agent_with_memory, memory = create_agent()

# ====================== CHAT INTERFACE ======================
# Initialize chat history in session state
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.messages.append({
        "role": "assistant",
        "content": "Hello! I'm your AI assistant. I can:\n• Generate image prompts\n• Calculate grades\n• Remember our entire conversation\n\nTry saying: *marks 88 92 76 94* or *best negative prompt for anime*"
    })

# Display all previous messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Input box at bottom
if prompt := st.chat_input("Type your message here..."):
    # Add user message
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Generate and display AI response
    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            response = agent_with_memory.invoke(
                {"input": prompt},
                config={"configurable": {"session_id": "streamlit_session"}}
            )
            reply = response["output"]
        st.markdown(reply)
        st.session_state.messages.append({"role": "assistant", "content": reply})

# ====================== SIDEBAR INFO ======================
with st.sidebar:
    st.header("Available Tools")
    st.success("Positive Prompt Generator")
    st.info("Negative Prompt Generator")
    st.warning("Grade Calculator")
    
    st.divider()
    st.header("About")
    st.write("• Full conversation memory")
    st.write("• Smart tool routing")
    st.write("• Fast inference via Groq")
    st.write("• 100% local & private")
    
    if st.button("Clear Chat History", type="secondary"):
        st.session_state.messages = []
        memory.clear()
        st.success("Chat cleared!")
        st.rerun()
    
    st.caption("Final Year Project 2025 • Made with Love")
    st.markdown("---")
    st.markdown("*Best project you'll ever submit*")